[TOC]

# æ¦‚ç‡è®º

## æå¤§ä¼¼ç„¶ä¼°è®¡

> æ¦‚ç‡æ˜¯é€šè¿‡å·²çŸ¥çš„æ¡ä»¶ï¼Œæ¨æµ‹äº‹ä»¶å‘ç”Ÿçš„å¯èƒ½æ€§ï¼›ä¼¼ç„¶åˆ™ç›¸åï¼Œæ˜¯åŸºäºå·²ç»ç¡®å®šçš„ç»“æœåæ¨äº§ç”Ÿè¿™ä¸ªç»“æœçš„å¯èƒ½æ€§ã€‚

$$
\thetaï¼šç¯å¢ƒå¯¹åº”çš„å‚æ•° \\
xï¼šäº‹ä»¶å‘ç”Ÿçš„ç»“æœ \\
æ¦‚ç‡ï¼šP(x|\theta) \quad Pæ˜¯å…³äºxçš„å‡½æ•°\\
ä¼¼ç„¶ï¼šL(\theta|x) \quad Læ˜¯å…³äº\thetaçš„å‡½æ•°
$$

æå¤§ï¼ˆæœ€å¤§ï¼‰ä¼¼ç„¶ä¼°è®¡ï¼šé€šè¿‡å·²çŸ¥ç»“æœæ¨æµ‹æœ€å¤§æ¦‚ç‡å¯¼è‡´è¿™äº›æ ·æœ¬ç»“æœå‡ºç°çš„æ¨¡å‹å‚æ•°ã€‚

## 2.4 Calculus

### æ¢¯åº¦

æˆ‘ä»¬å¯ä»¥è¿ç»“ä¸€ä¸ªå¤šå…ƒå‡½æ•°å¯¹å…¶æ‰€æœ‰å˜é‡çš„åå¯¼æ•°ï¼Œä»¥å¾—åˆ°è¯¥å‡½æ•°çš„*æ¢¯åº¦*ï¼ˆgradientï¼‰å‘é‡ã€‚
å…·ä½“è€Œè¨€ï¼Œè®¾å‡½æ•°$f:\mathbb{R}^n\rightarrow\mathbb{R}$çš„è¾“å…¥æ˜¯ä¸€ä¸ª$n$ç»´å‘é‡$\mathbf{x}=[x_1,x_2,\ldots,x_n]^\top$ï¼Œå¹¶ä¸”è¾“å‡ºæ˜¯ä¸€ä¸ªæ ‡é‡ã€‚
å‡½æ•°$f(\mathbf{x})$ç›¸å¯¹äº$\mathbf{x}$çš„æ¢¯åº¦æ˜¯ä¸€ä¸ªåŒ…å«$n$ä¸ªåå¯¼æ•°çš„å‘é‡:

$$\nabla_{\mathbf{x}} f(\mathbf{x}) = \bigg[\frac{\partial f(\mathbf{x})}{\partial x_1}, \frac{\partial f(\mathbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_n}\bigg]^\top,$$

å…¶ä¸­$ \nabla_{\mathbf{x}} f(\mathbf{x}) $é€šå¸¸åœ¨æ²¡æœ‰æ­§ä¹‰æ—¶è¢«$\nabla f(\mathbf{x})$å–ä»£ã€‚

å‡è®¾$\mathbf{x}$ä¸º$n$ç»´å‘é‡ï¼Œåœ¨å¾®åˆ†å¤šå…ƒå‡½æ•°æ—¶ç»å¸¸ä½¿ç”¨ä»¥ä¸‹è§„åˆ™:

* å¯¹äºæ‰€æœ‰$\mathbf{A} \in \mathbb{R}^{m \times n}$ï¼Œéƒ½æœ‰$\nabla_{\mathbf{x}} \mathbf{A} \mathbf{x} = \mathbf{A}^\top$
* å¯¹äºæ‰€æœ‰$\mathbf{A} \in \mathbb{R}^{n \times m}$ï¼Œéƒ½æœ‰$\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A}  = \mathbf{A}$
* å¯¹äºæ‰€æœ‰$\mathbf{A} \in \mathbb{R}^{n \times n}$ï¼Œéƒ½æœ‰$\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A} \mathbf{x}  = (\mathbf{A} + \mathbf{A}^\top)\mathbf{x}$
* $\nabla_{\mathbf{x}} \|\mathbf{x} \|^2 = \nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{x} = 2\mathbf{x}$

åŒæ ·ï¼Œå¯¹äºä»»ä½•çŸ©é˜µ$\mathbf{X}$ï¼Œéƒ½æœ‰$\nabla_{\mathbf{X}} \|\mathbf{X} \|_F^2 = 2\mathbf{X}$â€‹ã€‚
æ­£å¦‚æˆ‘ä»¬ä¹‹åå°†çœ‹åˆ°çš„ï¼Œæ¢¯åº¦å¯¹äºè®¾è®¡æ·±åº¦å­¦ä¹ ä¸­çš„ä¼˜åŒ–ç®—æ³•æœ‰å¾ˆå¤§ç”¨å¤„ã€‚

> å…³äºæ¢¯åº¦å‘é‡æ˜¯è¡Œå‘é‡è¿˜æ˜¯åˆ—å‘é‡ï¼Ÿ
>
> éƒ½ä¸æ˜¯ï¼Œè¡Œå‘é‡å’Œåˆ—å‘é‡æ˜¯ä»çŸ©é˜µçš„è§’åº¦æ¥æè¿°å‘é‡æ—¶æ‰ç‰¹æœ‰çš„ï¼Œæ™®é€šå‘é‡å¹¶æ²¡æœ‰å¿…é¡»æ”¾åˆ°çŸ©é˜µä¸­å»ï¼Œä¹Ÿæ²¡æœ‰æ‰€è°“å¿…é¡»æ˜¯è¡Œå‘é‡æˆ–è€…åˆ—å‘é‡çš„è¯´æ³•


### ç»ƒä¹ 

> ç»˜åˆ¶å‡½æ•°$y = f(x) = x^3 - \frac{1}{x}$å’Œå…¶åœ¨$x = 1$â€‹å¤„åˆ‡çº¿çš„å›¾åƒã€‚

```python
import numpy as np
import matplotlib.pyplot as plt

def func(x):
    return x ** 3 - 1 / x
def numerical_lim(f,x):
    h = 1e-4
    return (f(x+h)-f(x))/h
def tangent_line(f, x):
    # då°±æ˜¯è°ƒç”¨numerical_diffæ±‚å¾—åœ¨xç‚¹ç‚¹å¯¼æ•°
    d = numerical_lim(f, x)
    # è¿™é‡Œç›´æ¥y=kx+bæ±‚æˆªï¼Œç®€å•ç²—æš´ï¼Œyå°±æ˜¯æˆªè·
    y = f(x) - d * x
    # ä½¿ç”¨lambdaåŒ¿åå‡½æ•°ï¼Œtæ˜¯å½¢å‚ï¼Œ'ï¼š'åæ˜¯è¦æ‰§è¡Œçš„å‡½æ•°è¡¨è¾¾å¼
    return lambda t: d * t + y

x = np.arange(0.1, 5, 0.1)
y = func(x)

plt.xlabel('x')
plt.ylabel('y')
# æŠŠå‡½æ•°ä½œä¸ºå½¢å‚æ—¶iï¼Œä¼ å…¥å®å‚å‡½æ•°æ—¶ï¼Œåªè¦å‡½æ•°åå³å¯ï¼Œä¸ç”¨()
tf = tangent_line(func,1)
# å› ä¸ºtfè¿”å›çš„æ˜¯lambdaå‡½æ•°ï¼Œæ‰€ä»¥è¦å¤šè°ƒä¸€æ¬¡å‡½æ•°
y2 = tf(x)
plt.plot(x, y)
plt.plot(x, y2, linestyle='--')
plt.show()

```

> æ±‚å‡½æ•°$f(\mathbf{x}) = 3x_1^2 + 5e^{x_2}$â€‹çš„æ¢¯åº¦ã€‚

$$
[6x_1,5e^{x_2}]
$$



> å‡½æ•°$f(\mathbf{x}) = \|\mathbf{x}\|_2$â€‹çš„æ¢¯åº¦æ˜¯ä»€ä¹ˆï¼Ÿ

$$
||x||_2 = \sqrt{\sum_{i=1}^{n}x_i^2} \\
=\sqrt{x_1^2 + x_2^2â€¦â€¦+x_n^2} \\
D(||x||_2)= \frac{1}{2\sqrt{\sum_{i=1}^{n}x_i^2}}D(\sum_{i=1}^{n}x_i^2) \\
= \frac{x_i}{\sqrt{\sum_{i=1}^{n}x_i^2}} \\
\nabla_x||x||_2 = [\frac{x_1}{\sqrt{\sum_{i=1}^{n}x_i^2}}â€¦â€¦\frac{x_n}{\sqrt{\sum_{i=1}^{n}x_i^2}}]
$$

> å°è¯•å†™å‡ºå‡½æ•°$u = f(x, y, z)$ï¼Œå…¶ä¸­$x = x(a, b)$ï¼Œ$y = y(a, b)$ï¼Œ$z = z(a, b)$çš„é“¾å¼æ³•åˆ™ã€‚

$$
\frac{\partial u}{\partial a} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial a} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial a} + \frac{\partial f}{\partial z} \frac{\partial z}{\partial a} \\
\frac{\partial u}{\partial b} = \frac{\partial f}{\partial x} \frac{\partial x}{\partial b} + \frac{\partial f}{\partial y} \frac{\partial y}{\partial b} + \frac{\partial f}{\partial z} \frac{\partial z}{\partial b} \\
$$

## 2.5 Automatic Differentiation

[[5åˆ†é’Ÿæ·±åº¦å­¦ä¹ ] #02 åå‘ä¼ æ’­ç®—æ³•](https://www.bilibili.com/video/BV1yG411x7Cc/?spm_id_from=333.337.search-card.all.click&vd_source=519c4464a364b8611b8a226be3cda0f6)

åœ¨PyTorchä¸­ï¼Œ`.requires_grad_(True)` æ˜¯ä¸€ä¸ªç”¨äºè®¾ç½®å¼ é‡ï¼ˆtensorï¼‰å±æ€§çš„æ–¹æ³•ï¼Œç”¨äºæŒ‡ç¤ºè®¡ç®—æ—¶æ˜¯å¦éœ€è¦è®¡ç®—æ¢¯åº¦ï¼ˆgradientï¼‰ã€‚å…·ä½“æ¥è¯´ï¼š

- `x.requires_grad_(True)` è¡¨ç¤ºå°†å¼ é‡ `x` çš„ `requires_grad` å±æ€§è®¾ç½®ä¸º `True`ï¼Œè¿™æ„å‘³ç€å½“å¯¹ `x` è¿›è¡Œæ“ä½œæ—¶ï¼ŒPyTorchä¼šè‡ªåŠ¨è·Ÿè¸ªå¯¹ `x` çš„è®¡ç®—ï¼Œå¹¶ä¸”åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ä¿ç•™æ¢¯åº¦ä¿¡æ¯ï¼Œä»¥ä¾¿åç»­è¿›è¡Œåå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ã€‚

é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šå°†éœ€è¦å‚ä¸æ¨¡å‹è®­ç»ƒçš„å‚æ•°è®¾ç½®ä¸º `requires_grad=True`ï¼Œä»¥ä¾¿åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è‡ªåŠ¨è®¡ç®—å‚æ•°çš„æ¢¯åº¦ï¼Œä»è€Œæ›´æ–°å‚æ•°ã€‚

ä¸¾ä¾‹è¯´æ˜ï¼š

```python
import torch

# åˆ›å»ºä¸€ä¸ªå¼ é‡
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)

# è®¾ç½® requires_grad=Trueï¼Œå³éœ€è¦è®¡ç®—æ¢¯åº¦
x.requires_grad_(True)

# è¿›è¡Œä¸€äº›è®¡ç®—
y = x.pow(2).sum()

# åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦
y.backward()

# è¾“å‡ºæ¢¯åº¦
print(x.grad)  # è¿™é‡Œå°†ä¼šè¾“å‡ºå¯¹åº”çš„æ¢¯åº¦å€¼
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°† `x` çš„ `requires_grad` å±æ€§è®¾ç½®ä¸º `True`ï¼Œç„¶åè¿›è¡Œäº†ä¸€äº›è®¡ç®—ï¼ˆè®¡ç®—äº† `x` çš„å¹³æ–¹å’Œ `y`ï¼‰ï¼Œç„¶åé€šè¿‡ `y.backward()` åå‘ä¼ æ’­è®¡ç®—äº† `y` å¯¹ `x` çš„æ¢¯åº¦ã€‚
![image-20240411201507888](https://1ees0n.oss-cn-qingdao.aliyuncs.com/OS/image-20240411201507888.png)

## 2.7 Documentation

ä¸ºäº†çŸ¥é“æ¨¡å—ä¸­å¯ä»¥è°ƒç”¨å“ªäº›å‡½æ•°å’Œç±»ï¼š

- æŸ¥æ‰¾æ¨¡å—çš„æ‰€æœ‰å±æ€§

```python
dir(torch.distributions)
```

é€šå¸¸å¯ä»¥å¿½ç•¥ä»¥â€œ`__`â€ï¼ˆåŒä¸‹åˆ’çº¿ï¼‰å¼€å§‹å’Œç»“æŸçš„å‡½æ•°ï¼Œå®ƒä»¬æ˜¯Pythonä¸­çš„ç‰¹æ®Šå¯¹è±¡ï¼Œ æˆ–ä»¥å•ä¸ªâ€œ`_`â€ï¼ˆå•ä¸‹åˆ’çº¿ï¼‰å¼€å§‹çš„å‡½æ•°ï¼Œå®ƒä»¬é€šå¸¸æ˜¯å†…éƒ¨å‡½æ•°ã€‚ æ ¹æ®å‰©ä½™çš„å‡½æ•°åæˆ–å±æ€§åï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçŒœæµ‹è¿™ä¸ªæ¨¡å—æä¾›äº†å„ç§ç”Ÿæˆéšæœºæ•°çš„æ–¹æ³•ï¼Œ åŒ…æ‹¬ä»å‡åŒ€åˆ†å¸ƒï¼ˆ`uniform`ï¼‰ã€æ­£æ€åˆ†å¸ƒï¼ˆ`normal`ï¼‰å’Œå¤šé¡¹åˆ†å¸ƒï¼ˆ`multinomial`ï¼‰ä¸­é‡‡æ ·ã€‚

- æŸ¥æ‰¾ç‰¹å®šå‡½æ•°å’Œç±»çš„ç”¨æ³•

æœ‰å…³å¦‚ä½•ä½¿ç”¨ç»™å®šå‡½æ•°æˆ–ç±»çš„æ›´å…·ä½“è¯´æ˜ï¼Œå¯ä»¥è°ƒç”¨`help`å‡½æ•°ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ¥æŸ¥çœ‹å¼ é‡`ones`å‡½æ•°çš„ç”¨æ³•ã€‚

```python
help(torch.ones)
```



# 3. çº¿æ€§ç¥ç»ç½‘ç»œ

## [3.1 çº¿æ€§å›å½’](https://zh.d2l.ai/chapter_linear-networks/linear-regression.html)

ç»™å®šä¸€ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯»æ‰¾æ¨¡å‹çš„æƒé‡$w$å’Œåç½®$b$â€‹ï¼Œ ä½¿å¾—æ ¹æ®æ¨¡å‹åšå‡ºçš„é¢„æµ‹å¤§ä½“ç¬¦åˆæ•°æ®é‡Œçš„çœŸå®ä»·æ ¼ã€‚ è¾“å‡ºçš„é¢„æµ‹å€¼ç”±è¾“å…¥ç‰¹å¾é€šè¿‡*çº¿æ€§æ¨¡å‹*çš„ä»¿å°„å˜æ¢å†³å®šï¼Œä»¿å°„å˜æ¢ç”±æ‰€é€‰æƒé‡å’Œåç½®ç¡®å®šã€‚

![image-20240415151504433](https://1ees0n.oss-cn-qingdao.aliyuncs.com/OS/image-20240415151504433.png)

## 3.4 softmaxå›å½’

softmaxå›å½’æ˜¯ä¸€ä¸ªå¤šç±»åˆ†ç±»é—®é¢˜

![image-20240428101910628](https://1ees0n.oss-cn-qingdao.aliyuncs.com/OS/image-20240428101910628.png)

è®¡ç®—è¿‡ç¨‹

![image-20240428103109002](https://1ees0n.oss-cn-qingdao.aliyuncs.com/OS/image-20240428103109002.png)

![image-20240428103203942](https://1ees0n.oss-cn-qingdao.aliyuncs.com/OS/image-20240428103203942.png)

æ‰€æœ‰è¾“å‡ºoï¼Œéƒ½è½¬åŒ–ä¸ºyï¼Œä¸”
$$
y_1+y_2+...+y_n = 1 \\
y_1,y_2,...,y_n \in [0,1]
$$
![image-20240428103528482](https://1ees0n.oss-cn-qingdao.aliyuncs.com/OS/image-20240428103528482.png)

- ç‹¬çƒ­ç¼–ç 

é¡¾åæ€ä¹‰ï¼Œå…¨è¿æ¥å±‚æ˜¯â€œå®Œå…¨â€è¿æ¥çš„ï¼Œå¯èƒ½æœ‰å¾ˆå¤šå¯å­¦ä¹ çš„å‚æ•°ã€‚ å…·ä½“æ¥è¯´ï¼Œå¯¹äºä»»ä½•å…·æœ‰ğ‘‘ä¸ªè¾“å…¥å’Œğ‘ä¸ªè¾“å‡ºçš„å…¨è¿æ¥å±‚ï¼Œ å‚æ•°å¼€é”€ä¸ºğ‘‚(ğ‘‘ğ‘)ï¼Œè¿™ä¸ªæ•°å­—åœ¨å®è·µä¸­å¯èƒ½é«˜å¾—ä»¤äººæœ›è€Œå´æ­¥ã€‚ å¹¸è¿çš„æ˜¯ï¼Œå°†ğ‘‘ä¸ªè¾“å…¥è½¬æ¢ä¸ºğ‘ä¸ªè¾“å‡ºçš„æˆæœ¬å¯ä»¥å‡å°‘åˆ°ğ‘‚(ğ‘‘ğ‘/ğ‘›)ï¼Œ å…¶ä¸­è¶…å‚æ•°ğ‘›å¯ä»¥ç”±æˆ‘ä»¬çµæ´»æŒ‡å®šï¼Œä»¥åœ¨å®é™…åº”ç”¨ä¸­å¹³è¡¡å‚æ•°èŠ‚çº¦å’Œæ¨¡å‹æœ‰æ•ˆæ€§ ([Zhang *et al.*, 2021](https://zh.d2l.ai/chapter_references/zreferences.html#id195))ã€‚

## æŸå¤±å‡½æ•°

### l2 loss

$$
l(y,y') = \frac{1}{2}(y-y')^2
$$

### l1 loss

$$
l(y,y') = |y-y'|
$$

### Huber's Robust Loss

$$
l(y,y') =  
 \left\{ \begin{aligned}
            & |y-y'| - \frac{1}{2}  \quad if |y-y'| > 1\\ 
            & \frac{1}{2}(y-y')^2  \quad otherwise\\
            \end{aligned} 
 \right.
$$



## ä¹¦ç±

[**æœºå™¨å­¦ä¹ ã€NLPé¢è¯•ä¸­å¸¸è€ƒåˆ°çš„çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°**](https://github.com/NLP-LOVE/ML-NLP)

[åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](https://zh.d2l.ai/)

[æœ€å…¨è¥¿ç“œä¹¦-å‘¨å¿—åã€Šæœºå™¨å­¦ä¹ ã€‹ç¬”è®°](https://zhuanlan.zhihu.com/p/134089340)



## è®ºæ–‡

[é¢ è¦†ä¼ ç»Ÿï¼Transformeræ—¶åºé¢„æµ‹é‡å¤§çªç ´](https://mp.weixin.qq.com/s?__biz=MzkzOTY0NTMyNw==&mid=2247484236&idx=1&sn=e4dbbd9640c3dd6859e4472d4f0a0fa3&chksm=c2ec83acf59b0abab5ad2abc7ee7a9695a29fbe49bc1092ae3c508a7ebd73987afd087972028&mpshare=1&srcid=040103UKG3Z2vtYv04jCYtSk&sharer_shareinfo=1f092967f8efff9edb1867ba900c9c9d&sharer_shareinfo_first=1f092967f8efff9edb1867ba900c9c9d&from=singlemessage&scene=1&subscene=10000&clicktime=1712479943&enterid=1712479943&sessionid=0&ascene=1&fasttmpl_type=0&fasttmpl_fullversion=7146881-zh_CN-zip&fasttmpl_flag=0&realreporttime=1712479943238&devicetype=android-33&version=2800303d&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&countrycode=CN&exportkey=n_ChQIAhIQOaGT3wpVE8lXJRE9%2FXS90RLoAQIE97dBBAEAAAAAAE20MzVeRHkAAAAOpnltbLcz9gKNyK89dVj0Uyn1OTecrCjuAwvmjsyOfGdeA8XkeX1Z93ybHB1zCnZGm%2FH7LFjF2myPqesVVkco%2FnhX7MdZEDJtqAraEt%2FiQcmn%2BDDDUNl1tfVW1UlMY39zNikAHbAOpRe0QEyddY%2BfiFIPsiOidSY%2BfpMgPbirR1plpf2xnGAlvP%2FGHwPx0Pe%2FgzbWjk2KxkNqk69sOM0Wk72Srq%2F2PQZ2Z%2FufvbQOXvPL47hucDEEv4sKl%2F%2BCQYYx9Htg2lQD9vXds8nIB1p5uqc%3D&pass_ticket=QJa%2FjUpiVUbVodWSegV0ONI5nlrkzF7ORXVOquNIPbic1Q0pu%2Fw43vmhgnDyIXiian%2BlPKkB5YXhCjUdvD1bcg%3D%3D&wx_header=3)
